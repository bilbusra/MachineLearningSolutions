{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!apt-get install -y libsndfile1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /opt/conda/lib/python3.7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nprint(sys.path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/rabitt/pysox.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pysox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sox\n# create transformer\ntfm = sox.Transformer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa \nfrom librosa import display\nimport os\nimport pandas as pd\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!add-apt-repository universe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt-get install -y libwavpack1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt install -y ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pysox\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt -qq install -y sox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer = sox.Transformer()  # create transformer ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pysox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pysox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfm.build('../input/ravdess-emotional-speech-audio/Actor_01/03-01-02-02-02-02-01.wav', 'input/ravdess-emotional-speech-audio/Actor_01/03-01-02-02-02-02-01.wav')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data, sampling_rate = librosa.load('../input/ravdess-emotional-speech-audio/Actor_01/03-01-02-02-02-02-01.wav')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"path = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_12/03-01-03-01-02-01-12.wav\"\nX, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \nfemale = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\nfemale = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\nprint(len(female))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nlibrosa.display.waveplot(data, sr=44100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/ravdess-emotional-speech-audio'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlst_spectogram_mfcc = []\n\nfor subdir, dirs, files in os.walk(path):\n  for file in files:\n      try:       \n        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n        #file = file[6:8]\n        #arr = mfccs, file\n        lst_spectogram_mfcc.append(mfccs)\n      except ValueError:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install spafe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pysox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy\nfrom spafe.utils import vis\nfrom spafe.features.lfcc import lfcc\n\nimport scipy.io.wavfile\n\n#%cd TurEV-DB\nlst_lfcc_X = []\n#np_lst_lfcc_X = np.array()\n# init input vars\nnum_ceps = 40\nlow_freq = 0\nhigh_freq = 8000\nnfilts = 60\nnfft = 512\ndct_type = 2,\nuse_energy = 0,\nlifter = 5\nnormalize = 1\n\nfor subdir, dirs, files in os.walk(path):\n    for file in files:\n      try:       \n        fs, sig = scipy.io.wavfile.read(os.path.join(subdir,file))\n        lfccs = np.mean(lfcc(sig=sig,\n             fs=22400,\n             num_ceps=num_ceps,\n             nfilts=nfilts), axis=0)\n        #print(type(lfccs))\n        lst_lfcc_X.append(lfccs)\n      except ValueError:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(lst_lfcc_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spafe.features.lpc import lpc, lpcc, lpc2cep\n\n#%cd TurEV-DB\nlst_lpc_X = []\n# init input vars\nnum_ceps = 26\nlow_freq = 0\nhigh_freq = 8000\nnfilts = 60\nnfft = 1024\ndct_type = 2,\nuse_energy = 0,\nlifter = 5\nnormalize = 1\n\nfor subdir, dirs, files in os.walk(path):\n    for file in files:\n      try:\n        fs, sig = scipy.io.wavfile.read(os.path.join(subdir,file))              \n        lpccs = np.mean(lpcc(sig=sig,\n               fs=fs,\n               num_ceps=num_ceps,\n               do_rasta=False),axis=0)\n        lst_lpc_X.append(lpccs)\n      except ValueError:\n        continue\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spafe.features.rplp import plp, rastaplp\n\n#%cd TurEV-DB\nlst_plp_X = []\n\n\nfor subdir, dirs, files in os.walk(path):\n    for file in files:\n      try:       \n        fs, sig = scipy.io.wavfile.read(os.path.join(subdir,file))\n        plps  = np.mean(plp(sig, fs=fs, num_ceps= 26), axis=0)\n        lst_plp_X.append(plps)\n      except ValueError:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_plp_rasta_X = []\n\n\nfor subdir, dirs, files in os.walk(path):\n    for file in files:\n      try:       \n        fs, sig = scipy.io.wavfile.read(os.path.join(subdir,file))\n        rasta_plps  = np.mean(rastaplp(sig, fs=fs, modelorder= 25), axis=0)\n        lst_plp_rasta_X.append(rasta_plps)\n      except ValueError:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/ravdess-emotional-speech-audio'\nlst_spectogram_X = []\nlst_y = []\n\nfor subdir, dirs, files in os.walk(path):\n  for file in files:\n      try:       \n        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n        freq_spect = np.abs(librosa.stft(X, n_fft=512, window='hamming', win_length=256, hop_length=128)) ** 2\n        # Compute mel spectrogram\n        #\n        mel_spect = librosa.feature.melspectrogram(S=freq_spect, sr=44100, n_mels=128, fmax=4000)\n        #specto = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n        log_mel_spectogram=np.mean(librosa.power_to_db(mel_spect))\n        file = file[6:8]\n        lst_spectogram_X.append(log_mel_spectogram)\n        lst_y.append(file)\n        #arr = log_mel_spectogram, file\n        #lst_spectogram.append(arr)\n      except ValueError:\n        continue\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.asarray(lst_spectogram_X).reshape(2880,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(lst_plp_rasta_X).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.hstack((np.asarray(lst_spectogram_mfcc), np.asarray(lst_spectogram_X).reshape(2880,1))).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.hstack((np.asarray(lst_spectogram_mfcc), np.asarray(lst_spectogram_X).reshape(2880,1)))\ny = np.asarray(lst_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(lst_spectogram_mfcc).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_mel = np.asarray(lst_spectogram_X)\n\nX_lfcc = np.array(lst_lfcc_X)\n\nX_plp = np.array(lst_plp_X)\n\nX_plp_rasta = np.array(lst_plp_rasta_X)\n\nX_lpc = np.array(lst_lpc_X)\nX_mfcc = np.array(lst_spectogram_mfcc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = LabelEncoder()\ny_new = np_utils.to_categorical(lb.fit_transform(np.ravel(lst_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_mfcc, X_test_mfcc, y_train_mfcc, y_test_mfcc = train_test_split(X_mfcc, y_new, test_size=0.2, random_state=5)\nX_train_mel, X_test_mel, y_train_mel, y_test_mel = train_test_split(X_mel, y_new, test_size=0.2, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_mfcc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_lfcc, X_test_lfcc, y_train_lfcc, y_test_lfcc = train_test_split(X_lfcc, y_new, test_size=0.2, random_state=5)\nX_train_lpc, X_test_lpc, y_train_lpc, y_test_lpc = train_test_split(X_lpc, y_new, test_size=0.2, random_state=5)\nX_train_mel, X_test_mel, y_train_mel, y_test_mel = train_test_split(X_mel, y_new, test_size=0.2, random_state=5)\nX_train_plp, X_test_plp, y_train_plp, y_test_plp = train_test_split(X_plp, y_new, test_size=0.2, random_state=5)\nX_train_plp_rasta, X_test_plp_rasta, y_train_plp_rasta, y_test_plp_rasta = train_test_split(X_plp_rasta, y_new, test_size=0.2, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.2, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()\nmodel.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\nmodel.add(keras.layers.Dense(100,activation='relu'))\n#model.add(keras.layers.Dense(5,activation='relu'))\n#model.add(keras.layers.Dropout(rate=0.2))\nmodel.add(keras.layers.Dense(8,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train,epochs=200,batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}